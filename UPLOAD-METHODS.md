# Upload Methods Comparison

This guide explains the two methods for uploading your course data to Pinecone and when to use each one.

## ğŸ“Š Quick Comparison

| Feature | Direct to Pinecone | Via Server API |
|---------|-------------------|----------------|
| **Server Required** | âŒ No | âœ… Yes |
| **Speed** | âš¡ Faster (parallel) | ğŸ¢ Slower (sequential) |
| **Best For** | Bulk uploads, initial setup | Testing, small updates |
| **Cache** | âŒ Doesn't clear cache | âœ… Automatically clears |
| **Dependencies** | OpenAI + Pinecone | Just axios |
| **Error Handling** | Batch-level | Document-level |
| **Progress Tracking** | âœ… Detailed | âœ… Detailed |

## Method 1: Direct Upload to Pinecone âš¡ (RECOMMENDED)

### When to Use
- âœ… **Initial bulk upload** of all course data
- âœ… **Large datasets** (100+ documents)
- âœ… **Server is not running** or not needed
- âœ… **Faster uploads** are priority
- âœ… **Production deployments**

### How to Use

```bash
node upload-direct-to-pinecone.js
```

### What It Does
1. Reads JSON files directly
2. Generates embeddings using OpenAI API
3. Uploads vectors to Pinecone in batches (100 at a time)
4. Shows detailed progress and statistics
5. **Does NOT require the server to be running**

### Advantages
- âš¡ **Much faster** - processes documents in parallel batches
- ğŸ¯ **More reliable** - batch uploads reduce network errors
- ğŸ’° **Cost effective** - fewer API calls
- ğŸ”§ **More control** - direct Pinecone SDK access
- ğŸ“Š **Better for large datasets**

### Disadvantages
- âŒ Doesn't automatically clear query cache (do manually if needed)
- âŒ Requires both OpenAI and Pinecone API keys

### Example Output
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Direct Upload to Pinecone - Course Data        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Environment variables verified
âœ“ Connected to index: your-index-name
âœ“ Loaded 29 documents

Generating embeddings and preparing vectors...
[1/29] Processing: academic-calendar-2025-26... âœ“
[2/29] Processing: course-fd-sport-performance... âœ“
...

Uploading vectors to Pinecone...
Batch 1/1 (29 vectors)... âœ“ Uploaded

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Upload Summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total documents:           29
Embeddings generated:      29
Vectors uploaded:          29
Namespace:                 ucl-courses
Index:                     your-index-name
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ SUCCESS! All course data uploaded to Pinecone
```

## Method 2: Upload via Server API ğŸŒ

### When to Use
- âœ… **Small updates** (1-10 documents)
- âœ… **Testing new documents** before bulk upload
- âœ… **Server is already running**
- âœ… **Need cache to be cleared** automatically
- âœ… **UI-based uploads** (using the web interface)

### How to Use

**Option A: Command Line**
```bash
# Start server first
node server.js

# Then upload in another terminal
node upload-course-data.js
```

**Option B: Web Interface**
1. Start server: `node server.js`
2. Open `http://localhost:3000`
3. Use the "Upload Document" sidebar

### What It Does
1. Sends documents to your Express server
2. Server generates embeddings
3. Server uploads to Pinecone
4. Automatically clears query cache
5. Updates server statistics

### Advantages
- âœ… **Automatic cache clearing** - keeps responses fresh
- âœ… **Integrates with server** - updates stats and logs
- âœ… **Simpler setup** - only needs server running
- âœ… **UI available** - can upload via web interface

### Disadvantages
- ğŸ¢ **Slower** - sequential uploads
- ğŸ“‰ **Less efficient** for bulk data
- âš ï¸ **Requires server** to be running

## ğŸ¯ Recommended Workflow

### For Initial Setup (First Time)
```bash
# Use Direct Upload (faster, no server needed)
node upload-direct-to-pinecone.js
```

### For Testing/Development
```bash
# Start server
node server.js

# Use web interface at http://localhost:3000
# Upload individual documents via UI
```

### For Updates (Adding New Modules)
```bash
# Option 1: Add to JSON and re-run direct upload
node upload-direct-to-pinecone.js

# Option 2: Use server API for small additions
node server.js  # in one terminal
node upload-course-data.js  # in another
```

### For Production Deployment
```bash
# Use direct upload in your deployment script
node upload-direct-to-pinecone.js

# This ensures data is loaded before server starts
```

## ğŸ“ Environment Variables Required

### Direct Upload
```env
PINECONE_API_KEY=your_key_here
PINECONE_INDEX_NAME=your_index_name
OPENAI_API_KEY=your_openai_key_here
```

### Server Upload
```env
PINECONE_API_KEY=your_key_here
PINECONE_INDEX_NAME=your_index_name
OPENAI_API_KEY=your_openai_key_here
GEMINI_API_KEY=your_gemini_key_here  # Only needed for chat
```

## ğŸ”§ Clearing the Cache

### If Using Direct Upload
After direct upload, clear the cache via API:

```bash
# Method 1: Using curl
curl -X POST http://localhost:3000/api/cache/clear

# Method 2: Using the web interface
# Navigate to settings (if available)

# Method 3: Restart the server
# Simply stop and restart: node server.js
```

### If Using Server Upload
Cache is automatically cleared - no action needed!

## ğŸ“Š Performance Comparison

**Test Setup:** 29 documents (course data)

| Metric | Direct Upload | Server API |
|--------|--------------|------------|
| **Upload Time** | ~15-20 seconds | ~30-40 seconds |
| **API Calls** | 29 (OpenAI) + 1 (Pinecone batch) | 29 (OpenAI) + 29 (Pinecone individual) |
| **Network Efficiency** | High (batched) | Lower (individual) |
| **Error Recovery** | Batch-level | Document-level |

## ğŸš¨ Troubleshooting

### Direct Upload Issues

**Error: "Missing required environment variables"**
```bash
# Make sure .env file exists and contains:
PINECONE_API_KEY=...
PINECONE_INDEX_NAME=...
OPENAI_API_KEY=...
```

**Error: "Failed to generate embedding"**
- Check OpenAI API key is valid
- Verify you have credits in OpenAI account
- Check network connection

**Error: "Failed to upload to Pinecone"**
- Verify Pinecone API key
- Ensure index exists and dimensions are correct (1536)
- Check Pinecone service status

### Server Upload Issues

**Error: "Server is not running"**
```bash
# Start the server first
node server.js
```

**Error: "Connection refused"**
- Verify server is running on correct port (3000)
- Check firewall settings
- Try `http://localhost:3000/api/health`

## ğŸ’¡ Pro Tips

1. **First Time Setup:** Use direct upload for speed
2. **Development:** Keep server running and use web UI
3. **Large Updates:** Use direct upload and restart server
4. **Small Changes:** Use server API or web UI
5. **CI/CD Pipelines:** Use direct upload in deployment scripts

## ğŸ“ Example Use Cases

### Use Case 1: New Semester Data
You need to add 50 new modules for next semester.

**Recommended:** Direct Upload
```bash
# 1. Add new data to uc-course-data.json
# 2. Run direct upload
node upload-direct-to-pinecone.js
# 3. Restart server to clear cache
```

### Use Case 2: Fix One Deadline
A single assessment deadline changed.

**Recommended:** Server Upload or Web UI
```bash
# Option A: Edit JSON and use server
node server.js
node upload-course-data.js

# Option B: Use web interface
# 1. Open http://localhost:3000
# 2. Upload single document via UI
```

### Use Case 3: Production Deployment
Deploying to cloud for the first time.

**Recommended:** Direct Upload in deploy script
```bash
# In your deployment script:
npm install
node upload-direct-to-pinecone.js
node server.js
```

---

## ğŸ“š Related Files

- `upload-direct-to-pinecone.js` - Direct upload script
- `upload-course-data.js` - Server API upload script
- `uc-course-data.json` - Year 1 course data
- `uc-course-data-year2.json` - Year 2 course data
- `COURSE-DATA-GUIDE.md` - Course data reference
- `README.md` - Main documentation

---

**Choose the method that best fits your workflow! ğŸš€**

